<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Chatbot</title>
  <link rel="stylesheet" href="bot_style.css">
</head>
<body>
  <div class="chatbot-container">
    <div class="chatbot-header">
      <div class="chatbot-title">Frank</div>
      <div class="chatbot-listening-controls">
        <label class="switch">
          <input type="checkbox" id="listen-checkbox" onchange="toggleListening()">
          <span class="slider"></span>
        </label>
        <span id="listening-status" class="listening-status">Not listening</span>
      </div>
    </div>

    <div class="chatbot-messages" id="messages"></div>

    <div class="chatbot-input">
      <input type="text" id="chat-input" placeholder="Type a message...">
      <button onclick="sendMessage()">Send</button>
    </div>
  </div>

  <script>
    let chatHistory = [];
    let intent = null;
    let lastSelector = null;
    let botMessage = null;
    const currentPage = window.parent.location.pathname.split("/").pop();

    // Function to get the summary of the last user message based on the current page
    // This function is called when the chatbot detects a confirmation or success page.
    function getSummary() {
      console.log("getSummary called for page:", currentPage);

      const patterns = {
        "confirm_transfer.html": { match: "You plan to send", emoji: /^✅\s*/ },
        "success.html": { match: "You successfully transfered", emoji: /^🎉\s*/ }
      };

      const pattern = patterns[currentPage];
      if (!pattern) {
        console.log("No pattern defined for this page.");
        return "";
      }

      console.log("Using pattern:", pattern);

      // Look for the last user message that matches
      for (let i = chatHistory.length - 1; i >= 0; i--) {
        const m = chatHistory[i];
        console.log("Checking message:", m);
        if (m.role === "user" && m.content.includes(pattern.match)) {
          const cleanedText = m.content.replace(pattern.emoji, '');
          console.log("Found matching message:", cleanedText);
          return cleanedText;
        }
      }

      console.log("No matching message found.");
      return "";
    }

    // Append a message to the chatbox
    // This function is called when the user sends a message or the assistant responds.
    function appendMessage(role, text, suppressTTS = false) {
      const messages = document.getElementById("messages");
      const div = document.createElement("div");
      div.className = "message " + role;
      div.innerText = text;
      messages.appendChild(div);
      messages.scrollTop = messages.scrollHeight;

      // Speak if the message is from assistant and on the listening mode
      if (role === "assistant" && listening && !suppressTTS) {
        if (currentPage === "confirm_transfer.html") {
          console.log("Confirm transfer page detected, checking for summary");
          const userLog = getSummary();
          if (userLog) {
            speak(userLog);
          }
        }

        if (currentPage === "success.html") {
          const userLog = getSummary();
          if (userLog) {
            speak(userLog);
          }
        }

        speak(text);
      }
    }
  
    // Highlight the element in the parent window
    // This function is called when the chatbot receives a selector from the backend
    function highlight(selector, lastInstruction = "mark-complete") {
      if (!selector) return;
      console.log("lastSelector and selector", lastSelector, selector);

      // Dehighlight the previous selector if it's different
      if (lastSelector && lastSelector !== selector) {
        console.log("dehighlighting in chatbot", lastSelector);
        window.parent.postMessage({selector: lastSelector, instruction: lastInstruction}, "*");
      }

      console.log("[Chatbot] Sending highlight to parent:", selector);
      // Highlight the new selector
      window.parent.postMessage({selector, instruction: "highlight"}, "*");
      lastSelector = selector; // Update the last selector
    }

    // FRANK UNIQUE FUNCTION: Perform an action on the parent page
    function performAction(selector, action, value = null) {
        window.parent.postMessage({ selector, instruction: action, value }, "*");
    }

    // Log user action to the chat history and sessionStorage
    function logUserAction(text) {
      appendMessage("user", text);
      chatHistory.push({ role: "user", content: text });
      sessionStorage.setItem("chatHistory", JSON.stringify(chatHistory));
    }

    // Update substep flags for the "Transfer Someone" page
    // This function checks the parent form fields to determine if the user has selected an account and entered an amount.
    // It returns an object with flags that indicate the progress of the substep.
    // This is used to track the user's progress in the transfer process.
    function updateSubstepFlagsForTransferSomeone() {
      const substep_flags = {};

      try {
        const parentDoc = window.parent.document;
        const account = parentDoc.querySelector("#from-account");
        const amount = parentDoc.querySelector("#amount");

        if (account && account.value !== "instruction") {
          substep_flags.account_chosen = true;
        }

        if (amount && parseFloat(amount.value) > 0) {
          substep_flags.amount_entered = true;
        }
      } catch (e) {
        console.warn("Unable to access parent form fields:", e);
      }

      return substep_flags;
    }

    // OPTION1: TTS function using server-side API
    // async function speak(text) {
    //   try {
    //     const response = await fetch("/speak", {
    //       method: "POST",
    //       headers: {
    //         "Content-Type": "application/json"
    //       },
    //       body: JSON.stringify({ text })
    //     });

    //     const result = await response.json();
    //     if (result.status === "success") {
    //       console.log("Speech played:", result.text);
    //     } else {
    //       console.error("TTS Error:", result.reason);
    //     }
    //   } catch (error) {
    //     console.error("Failed to fetch /speak:", error);
    //   }
    // }

    // OPTION2: TTS function using Web Speech API
    let voicesReady = false;

    speechSynthesis.onvoiceschanged = () => {
      voicesReady = true;
      console.log("Voices loaded:", speechSynthesis.getVoices());
    };

    function speak(text) {
      if (!('speechSynthesis' in window)) {
        console.warn("This browser does not support speech synthesis.");
        return;
      }

      if (!voicesReady) {
        console.warn("Voices not ready yet — skipping TTS:", text);
        return;
      }

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';

      const voices = speechSynthesis.getVoices();
      const voice = voices.find(v => v.lang === 'en-US' && v.name.includes("Google"));
      if (voice) {
        utterance.voice = voice;
        console.log("Using voice:", voice.name);
      } else {
        console.log("No Google US English voice found — using default en-US");
      }

      utterance.onstart = function() {
        if (listening && recognition) {
          console.log("Pausing recognition during TTS");
          recognition.stop();
        }
      };

      utterance.onend = function() {
        if (listening && recognition) {
          console.log("Resuming recognition after TTS");
          recognition.start();
        }
      };

      speechSynthesis.speak(utterance);
    }

  
    // sendMessage() fires when: 
    // 1) The user types a message (e.g., "what's next?") 
    // 2) the page auto-resumes on load (newPageLoaded=True)
    async function sendMessage(newPageLoaded = false, substepUpdated = false, overrideTranscript = null) {
      console.log("sendMessage called", { newPageLoaded});
      const input = document.getElementById("chat-input");
      const message = newPageLoaded ? "resuming" : (overrideTranscript ? overrideTranscript : input.value.trim()); // Get user input or use overrideMessage if auto is true.
      if (!message && !newPageLoaded) return; // Don't send empty messages unless the page just loaded.
      
      let substep_flags = {};
      if (currentPage === "send_to_alex.html") {
        substep_flags = updateSubstepFlagsForTransferSomeone();
      }
  
      // Append the message to the chat history and display it
      if (!newPageLoaded) {
        appendMessage("user", message);
        chatHistory.push({ role: "user", content: message });
      }

      input.value = "";
  
      const res = await fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          messages: chatHistory,
          newPageLoaded,
          substepUpdated,
          intent,
          currentPage,
          substep_flags,  // ✅ Send subtask progress
          assistant: "frank"    // FRANK UNIQUE PARAMETER: specify the assistant name
        })
      });
  
      const data = await res.json();
      console.log("data from backend", data)
      // console.log("flags", data.substep_flags);

      intent = data.intent || intent ; // Use the intent from the response or keep the current one
      selector = data.selector || null;
      botMessage = data.botMessage || "Hmmm not sure if I understand. Please tell me your goal.";
      
      appendMessage("assistant", botMessage);
      chatHistory.push({ role: "assistant", content: botMessage });
      sessionStorage.setItem("chatHistory", JSON.stringify(chatHistory));
  
      if (intent && intent !== "unknown") {
        sessionStorage.setItem("intent", intent);
      }
      
      if (selector) {
        sessionStorage.setItem("selector", selector);
        highlight(selector);
      }

      // FRANK UNIQUE PART: This checks if the backend returned an action (like "fill"/"click"/"select") and sends it to the main page after a short delay.
      if (selector && data.action) {
        setTimeout(() => performAction(selector, data.action, data.value), 3000);
    }
    }
  
    // runs only once when chatbot.html is first rendered in the browser (i.e., when the iframe is inserted into the DOM and loads the chatbot page).
    window.addEventListener("DOMContentLoaded", () => {
      // Load chat history, intent
      console.log("DOMContentLoaded");  // 🔍 baseline check
      chatHistory = JSON.parse(sessionStorage.getItem("chatHistory") || "[]");
      intent = sessionStorage.getItem("intent") || null;

      // Restore listening state to show the listening checkbox and status consistently
      const storedListening = sessionStorage.getItem("listening");
      if (storedListening === "true") {
        listening = true;
        document.getElementById("listen-checkbox").checked = true;
        document.getElementById("listening-status").textContent = "Listening...";
        if (recognition) recognition.start();
      } else {
        listening = false;
        document.getElementById("listen-checkbox").checked = false;
        document.getElementById("listening-status").textContent = "Not listening";
      }

      // Restore chatbox and history
      for (const m of chatHistory) appendMessage(m.role, m.content, suppressTTS=true); // Re-render chat history
      const input = document.getElementById("chat-input");
      input.addEventListener("keydown", (e) => {
        if (e.key === "Enter") sendMessage();
      });

      // Automatically send a message: if there's no intent, asking for intent. If there's, resuming the conversation.
      if (!intent) {
        appendMessage("assistant", "Hi! I'm Frank. Tell me what to do, and I'll take care of it.");
      } else {
        // Figure out the step based on intent + page
        // This logic is only run when the chatbot is first loaded, not on every message sent.
        // This is to ensure that the chatbot can resume the conversation from the correct step.
        console.log("calling sendMessage for resuming")
        sendMessage(newPageLoaded = true);
      }

      if (window.parent.location.pathname.endsWith("send_to_alex.html")) {
        const parentDoc = window.parent.document;
        console.log("parentDoc", parentDoc);

        parentDoc.querySelector("#from-account")?.addEventListener("change", () => {
          sendMessage(substepUpdated = true);
        });

        parentDoc.querySelector("#amount")?.addEventListener("change", () => {
          sendMessage(substepUpdated = true);
        });

      }
    });
  
    // This listens for messages from the parent window (the main app) to log user actions.
    window.addEventListener("message", (event) => {
      const { instruction, text } = event.data;
      if (instruction === "log" && typeof text === "string") {
        logUserAction(text);
      }
    });
  
    // This saves the chat history, step name, and intent to sessionStorage before the page is unloaded.
    window.addEventListener("beforeunload", () => {
      sessionStorage.setItem("chatHistory", JSON.stringify(chatHistory));
      sessionStorage.setItem("intent", intent);
    });

    // Speech Recognition setup
    let recognition;
    let listening = false;  // global listening flag

    if ('webkitSpeechRecognition' in window) {
      recognition = new webkitSpeechRecognition();  // Chrome
    } else if ('SpeechRecognition' in window) {
      recognition = new SpeechRecognition();  // Firefox
    }

    if (recognition) {
      recognition.continuous = false;  // Not enable continuous listening
      recognition.interimResults = false;
      recognition.lang = 'en-US';

      recognition.onresult = function(event) {
        const transcript = event.results[0][0].transcript;
        console.log("You said:", transcript);
        sendMessage(false, false, transcript);  // pass as param
      };

      recognition.onerror = function(event) {
        console.error("Speech recognition error:", event.error);

        if (event.error === "no-speech") {
          // No alert — user was silent, that's OK
          return;
        }

        alert("Speech recognition error: " + event.error);
      };

      recognition.onend = function() {
        if (listening) {
          console.log("Recognition ended, restarting...");
          recognition.start();  // auto-restart for next speech
        }
      };

      function toggleListening() {
        const isChecked = document.getElementById("listen-checkbox").checked;
        const statusLabel = document.getElementById("listening-status");

        if (isChecked && !listening) {
          recognition.start();
          listening = true;
          statusLabel.textContent = "Listening...";
          sessionStorage.setItem("listening", "true");  // Save ON
          console.log("Listening started...");
        } else if (!isChecked && listening) {
          recognition.stop();
          listening = false;
          statusLabel.textContent = "Not listening";
          sessionStorage.setItem("listening", "false");  // Save OFF
          console.log("Listening stopped.");
        }
      }


    } else {
      function toggleListening() {
        alert("Speech recognition is not supported in this browser.");
      }
    }
  </script>
</body>
</html>